<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/sparkutils/shim/package.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>package com.sparkutils
</span>2 <span style=''>
</span>3 <span style=''>import org.apache.spark.sql.SparkSession
</span>4 <span style=''>import org.apache.spark.sql.catalyst.expressions.{Expression, If, IsNull, Literal}
</span>5 <span style=''>import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan
</span>6 <span style=''>import org.apache.spark.sql.catalyst.rules.Rule
</span>7 <span style=''>import org.apache.spark.sql.types.DataType
</span>8 <span style=''>
</span>9 <span style=''>/**
</span>10 <span style=''> * A collection of functions with possibly varying behaviour across Spark versions.  Should actual implementations fracture they will be implemented as part of ShimUtils but the interface will remain to proxy the calls.
</span>11 <span style=''> */
</span>12 <span style=''>package object shim {
</span>13 <span style=''>
</span>14 <span style=''>  /**
</span>15 <span style=''>   * Registers a session only plan via experimental methods when isPresentFilter is not true
</span>16 <span style=''>   * @param logicalPlan
</span>17 <span style=''>   * @param isPresentFilter a filter that should return true when the plan is identical and it should not be added
</span>18 <span style=''>   * @return true if the plan has been added
</span>19 <span style=''>   */
</span>20 <span style=''>  def registerSessionPlan(logicalPlan: Rule[LogicalPlan])(isPresentFilter: Rule[LogicalPlan] =&gt; Boolean): Boolean = {
</span>21 <span style=''>    val methods = </span><span style='background: #F0ADAD'>SparkSession.active.sessionState.experimentalMethods</span><span style=''>
</span>22 <span style=''>    if (</span><span style='background: #F0ADAD'>methods.extraOptimizations.forall(!isPresentFilter(_))</span><span style=''>) </span><span style='background: #F0ADAD'>{
</span>23 <span style=''></span><span style='background: #F0ADAD'>      methods.extraOptimizations = methods.extraOptimizations :+ logicalPlan
</span>24 <span style=''></span><span style='background: #F0ADAD'>      true
</span>25 <span style=''></span><span style='background: #F0ADAD'>    }</span><span style=''> else
</span>26 <span style=''>      </span><span style='background: #F0ADAD'>false</span><span style=''>
</span>27 <span style=''>  }
</span>28 <span style=''>
</span>29 <span style=''>  // below are for Framless support
</span>30 <span style=''>  def deriveUnitLiteral: Expression = </span><span style='background: #F0ADAD'>Literal.fromObject(())</span><span style=''>
</span>31 <span style=''>
</span>32 <span style=''>  /**
</span>33 <span style=''>   * If the path is null then uses a null literal with dataType, if it's not null it uses the nonNullExpr
</span>34 <span style=''>   * @param dataType
</span>35 <span style=''>   * @param path
</span>36 <span style=''>   * @param nonNullExpr
</span>37 <span style=''>   * @return
</span>38 <span style=''>   */
</span>39 <span style=''>  def ifIsNull(dataType: DataType, path: Expression, nonNullExpr: Expression): Expression = {
</span>40 <span style=''>    val nullExpr = </span><span style='background: #F0ADAD'>Literal.create(null, dataType)</span><span style=''>
</span>41 <span style=''>
</span>42 <span style=''>    </span><span style='background: #F0ADAD'>If(IsNull(path), nullExpr, nonNullExpr)</span><span style=''>
</span>43 <span style=''>  }
</span>44 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Tests</th>
        <th>Code</th>
      </tr><tr>
        <td>
          21
        </td>
        <td>
          1
        </td>
        <td>
          979
          -
          1031
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.internal.SessionState.experimentalMethods
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.SparkSession.active.sessionState.experimentalMethods
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          244
        </td>
        <td>
          1040
          -
          1094
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.IterableLike.forall
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          methods.extraOptimizations.forall(((x$1: org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]) =&gt; isPresentFilter.apply(x$1).unary_!))
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          417
        </td>
        <td>
          1096
          -
          1191
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          {
  methods.extraOptimizations_=(methods.extraOptimizations.:+[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan], Seq[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]](logicalPlan)(collection.this.Seq.canBuildFrom[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]));
  true
}
        </td>
      </tr><tr>
        <td>
          22
        </td>
        <td>
          350
        </td>
        <td>
          1074
          -
          1093
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          isPresentFilter.apply(x$1).unary_!
        </td>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          169
        </td>
        <td>
          1104
          -
          1174
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.ExperimentalMethods.extraOptimizations_=
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          methods.extraOptimizations_=(methods.extraOptimizations.:+[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan], Seq[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]](logicalPlan)(collection.this.Seq.canBuildFrom[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]))
        </td>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          70
        </td>
        <td>
          1160
          -
          1160
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.collection.Seq.canBuildFrom
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          collection.this.Seq.canBuildFrom[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]
        </td>
      </tr><tr>
        <td>
          23
        </td>
        <td>
          384
        </td>
        <td>
          1133
          -
          1174
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.SeqLike.:+
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          methods.extraOptimizations.:+[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan], Seq[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]]](logicalPlan)(collection.this.Seq.canBuildFrom[org.apache.spark.sql.catalyst.rules.Rule[org.apache.spark.sql.catalyst.plans.logical.LogicalPlan]])
        </td>
      </tr><tr>
        <td>
          24
        </td>
        <td>
          511
        </td>
        <td>
          1181
          -
          1185
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          true
        </td>
      </tr><tr>
        <td>
          26
        </td>
        <td>
          2
        </td>
        <td>
          1203
          -
          1208
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          26
        </td>
        <td>
          234
        </td>
        <td>
          1203
          -
          1208
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          30
        </td>
        <td>
          337
        </td>
        <td>
          1288
          -
          1310
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.Literal.fromObject
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.expressions.Literal.fromObject(())
        </td>
      </tr><tr>
        <td>
          40
        </td>
        <td>
          259
        </td>
        <td>
          1618
          -
          1648
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.Literal.create
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.expressions.Literal.create(null, dataType)
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          379
        </td>
        <td>
          1654
          -
          1693
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.If.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.expressions.If.apply(org.apache.spark.sql.catalyst.expressions.IsNull.apply(path), nullExpr, nonNullExpr)
        </td>
      </tr><tr>
        <td>
          42
        </td>
        <td>
          72
        </td>
        <td>
          1657
          -
          1669
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.catalyst.expressions.IsNull.apply
        </td>
        <td>
          
        </td>
        <td style="background: #F0ADAD">
          org.apache.spark.sql.catalyst.expressions.IsNull.apply(path)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>